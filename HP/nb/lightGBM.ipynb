{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "ee-sOv-S0zcT"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as ltb\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train dataset from the csv file\n",
    "train_df = pd.read_csv(\"../Datasets/new_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the week number from the 'year_week' column as an integer\n",
    "train_df['nweek'] = train_df['year_week'].map(lambda x: str(x)[-2:]).astype(np.int64)\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Extract year and month from the 'date' column and creating new columns for them\n",
    "train_df['year'], train_df['month'] = train_df['date'].dt.year, train_df['date'].dt.month\n",
    "\n",
    "# Dropping the 'date' and 'id' columns from the dataframe\n",
    "train_df = train_df.drop(['date'],axis=1)\n",
    "train_df = train_df.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows from train_df where the year column is either 2021, 2020 or 2019\n",
    "train_2021 = train_df[(train_df['year'] == 2021) | (train_df['year'] == 2020) | (train_df['year'] == 2019)]\n",
    "\n",
    "# Selecting rows from train_df where the year column is 2022\n",
    "train_2022 = train_df[train_df['year'] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating features and target variables for the year 2021 data\n",
    "X = train_2021.drop(columns=['inventory_units'])\n",
    "Y = train_2021['inventory_units']\n",
    "\n",
    "# Creating features and target variables for the year 2022 data\n",
    "X_2022 = train_2022.drop(columns=['inventory_units'])\n",
    "Y_2022 = train_2022['inventory_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop three columns from the dataframe X\n",
    "X = X.drop(columns = ['Unnamed: 0', 'year_week', 'sales_units'])\n",
    "\n",
    "# Drop three columns from the dataframe X_2022\n",
    "X_2022 = X_2022.drop(columns = ['Unnamed: 0', 'year_week', 'sales_units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='dart', importance_type='gain', learning_rate=0.15,\n",
       "              max_depth=200, n_estimators=50, num_leaves=30)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LightGBM regressor model with specified hyperparameters\n",
    "model = ltb.LGBMRegressor(boosting_type = 'dart',\n",
    "                          num_leaves = 30,\n",
    "                          max_depth = 200,\n",
    "                          learning_rate = 0.15,\n",
    "                          n_estimators = 50,\n",
    "                          importance_type  = 'gain',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS train: 42.459893747029426\n",
      "RMS test: 162.03091977906104\n"
     ]
    }
   ],
   "source": [
    "# Predict inventory units for training set and calculate root mean squared error (RMS) for training set\n",
    "y_predicted_train = model.predict(X_train)\n",
    "rms_train = mean_squared_error(y_train, y_predicted_train, squared=False)\n",
    "print(f\"RMS train: {rms_train}\")\n",
    "\n",
    "# Predict inventory units for test set and calculate root mean squared error (RMS) for test set\n",
    "y_predicted_test = model.predict(X_test)\n",
    "rms_test = mean_squared_error(y_test, y_predicted_test, squared=False)\n",
    "print(f\"RMS test: {rms_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS 2022: 137.37992871120846\n"
     ]
    }
   ],
   "source": [
    "# Predict inventory units for 2022 using the trained model and calculate RMSE\n",
    "y_predicted_train = model.predict(X_2022)\n",
    "rms_train = mean_squared_error(Y_2022, y_predicted_train, squared=False)\n",
    "print(f\"RMS 2022: {rms_train}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
