{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoded data from a CSV file\n",
    "encoded = pd.read_csv('../Datasets/ecoded.csv',sep=';')\n",
    "\n",
    "# Convert the embedding column from a string to a list of floats\n",
    "encoded.embedding = encoded.embedding.map(lambda x: [float(num) for num in x[1:-1].split(' ') if num != ''])\n",
    "\n",
    "# Create a new DataFrame from the embeddings list and add it to the encoded DataFrame\n",
    "embeddings = pd.DataFrame(encoded.embedding.to_list(), columns=['embedding_1','embedding_2','embedding_3','embedding_4'])\n",
    "encoded = pd.concat([encoded,embeddings],axis=1).drop(columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'gt' and 'product_id' columns from the encoded DataFrame and assign the result to X\n",
    "X = encoded.drop(columns=['gt','product_id'])\n",
    "\n",
    "# Assign the 'gt' column from the encoded DataFrame to Y\n",
    "Y = encoded['gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# Shuffle the data and set a random seed for reproducibility\n",
    "X_train, X_test, y_train, y_test   = train_test_split(X,Y,shuffle=True,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best XGBoost hyperparameters from two pickle files\n",
    "# best_params1 from 'best_params_xgboost.pkl'\n",
    "# best_params2 from 'best_params_xgboost_2.pkl'\n",
    "with open('best_params_xgboost_2.pkl','rb') as file2, open('best_params_xgboost.pkl','rb') as file1:\n",
    "    best_params1 = pickle.load(file1)\n",
    "    best_params2 = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting Regressor with the best hyperparameters from the pickle file\n",
    "xgboost_encoded = GradientBoostingRegressor(**best_params2)\n",
    "\n",
    "# Fit the model using the training data\n",
    "result_f_sklearn_gooddf = xgboost_encoded.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 66.68456764837829\n",
      "test: 111.94892310939883\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict the target variable for the testing and training sets\n",
    "y_predicted_test = xgboost_encoded.predict(X_test)\n",
    "y_predicted_train = xgboost_encoded.predict(X_train)\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) for the testing and training sets\n",
    "rms_test = mean_squared_error(y_test, y_predicted_test, squared=False)\n",
    "rms_train = mean_squared_error(y_train, y_predicted_train, squared=False)\n",
    "\n",
    "# Print the RMSE for the testing and training sets\n",
    "print(f'train: {rms_train}\\ntest: {rms_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:   59.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Define a GridSearchCV object to search for the best hyperparameters\n",
    "gsc1 = GridSearchCV(\n",
    "            estimator=GradientBoostingRegressor(),\n",
    "            param_grid={\"n_estimators\": list(range(60,80,10)),\n",
    "                        \"learning_rate\": [0.1,0.05],\n",
    "                        \"max_depth\": [5,10],#,20],\n",
    "                        'min_impurity_decrease':[2],#,10],\n",
    "                        'min_samples_split':[50,100],\n",
    "                        'min_samples_leaf':[10,20],\n",
    "                        'max_features':['auto'],\n",
    "                        'max_leaf_nodes':list(range(100,300,100)),\n",
    "                        'ccp_alpha':[0.1,0.5]},\n",
    "            cv=5, scoring='neg_root_mean_squared_error', verbose=10, n_jobs=-1)\n",
    "\n",
    "# Use the GridSearchCV object to search for the best hyperparameters\n",
    "grid_result_encoded = gsc1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:-91.48912846917312\n",
      "test:-106.76120430417743\n"
     ]
    }
   ],
   "source": [
    "# Print the training and testing scores of the GridSearchCV object\n",
    "print(f'train:{grid_result_encoded.score(X_train,y_train)}\\ntest:{grid_result_encoded.score(X_test, y_test)}')\n",
    "\n",
    "# Store the training and testing scores in a tuple\n",
    "results = (grid_result_encoded.score(X_train,y_train), grid_result_encoded.score(X_test, y_test))\n",
    "# rmse.append(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
